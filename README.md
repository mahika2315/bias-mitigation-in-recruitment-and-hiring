# âš–ï¸ Recruitment Bias Mitigation Tool

## ğŸ“Œ Overview
The **Recruitment Bias Mitigation Tool** is a **Streamlit-based application** that enables users to analyze and mitigate bias in recruitment datasets. It provides insights into demographic parity difference and equalized odds difference and applies bias mitigation using **Fairlearn's ExponentiatedGradient** method.

## âœ¨ Features
- ğŸ“Š **Upload a recruitment dataset** (CSV format)
- ğŸ¯ **Select target and sensitive attributes** for bias analysis
- ğŸ† **Evaluate bias metrics** (such as Demographic Parity Difference, Equalized Odds Difference)
- ğŸ—ï¸ **Apply bias mitigation** using Fairlearn
- ğŸ“ˆ **Visualizations**: Confusion Matrix and ROC Curve
- ğŸ’¾ **Download results** after analysis and mitigation

## ğŸ› ï¸ Installation
To run this project locally, follow these steps:

### 1ï¸âƒ£ Clone the Repository
```sh
git clone https://github.com/mripradhan/bias-mitigation-tool.git
cd bias-mitigation-tool
```

### 2ï¸âƒ£ Install Dependencies
Create a virtual environment (optional but recommended):
```sh
python -m venv env
source env/bin/activate  # On Windows use: env\Scripts\activate
```
Then, install the required libraries:
```sh
pip install -r requirements.txt
```

Create a `.env` file and add your API key:
```sh
GROQ_API_KEY="yourapikey"' > .env
```

### 3ï¸âƒ£ Run the Streamlit App
```sh
streamlit run biasmitigation.py
```

## ğŸ“‚ Project Structure
```
ğŸ“ bias-mitigation-tool/
â”‚-- ğŸ“„ biasmitigation.py      # Main Streamlit application
â”‚-- ğŸ“„ requirements.txt       # List of dependencies
â”‚-- ğŸ“„ README.md              # Documentation
```

## ğŸ—ï¸ How to Use
1. **Upload your dataset**: Select a CSV file containing recruitment-related data.
2. **Select columns**: Choose a sensitive attribute (e.g., gender, race) and a target column (e.g., hired or not).
3. **Analyze bias**: The tool computes bias metrics and visualizes results.
4. **Mitigate bias**: Apply Fairlearn's ExponentiatedGradient method to reduce bias.
5. **Download results**: Save the processed predictions for further evaluation.

## ğŸ” Bias Metrics Explained
- **Demographic Parity Difference**: Measures if different groups have equal selection rates.
- **Equalized Odds Difference**: Measures if predictions are equally accurate across groups.

## ğŸ› ï¸ Technologies Used
- **Python** ğŸ
- **Streamlit** ğŸ“Š
- **Fairlearn** âš–ï¸
- **scikit-learn** ğŸ¤–
- **Matplotlib & Seaborn** ğŸ“ˆ

## ğŸ“œ License
This project is licensed under the **MIT License**.

## ğŸ¤ Contributing
Contributions are welcome! Feel free to fork this repo, open issues, or submit pull requests.

---
ğŸš€ **Empower ethical AI in recruitment with this bias mitigation tool!**

